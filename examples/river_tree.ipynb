{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River Tree\n",
    "\n",
    "An example workflow for gathering NHD Plus data and generating a tree.\n",
    "\n",
    "AJ: works with ats_meshing_dev conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append('/Users/ajc/Core/SimDataInputs/WorkSpace/ats-88/ats_meshing/workflow/')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import shapely\n",
    "import logging\n",
    "sys.path.append('/Users/ajc/anaconda3/envs/ats_meshing/')\n",
    "import workflow\n",
    "import workflow.source_list\n",
    "import workflow.conf\n",
    "import workflow.ui\n",
    "import workflow.utils\n",
    "import workflow.plot\n",
    "workflow.conf.rcParams['data dir'] = os.path.join(os.getcwd(),'..','data')\n",
    "\n",
    "workflow.ui.setup_logging(1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajc/anaconda3/envs/ats_meshing_dev/lib/python3.7/site-packages/fiona/collection.py:336: FionaDeprecationWarning: Collection slicing is deprecated and will be disabled in a future version.\n",
      "  return self.session.__getitem__(item)\n"
     ]
    }
   ],
   "source": [
    "# open a shapefile for use here\n",
    "#use fiona to read shape file\n",
    "manager_shp = workflow.source_list.FileManagerShape('../data/hydrologic_units/others/coweeta_basin/coweeta_basin.shp')\n",
    "shp_profile,shp = manager_shp.get_shape()\n",
    "shply = workflow.utils.shply(shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-02 16:15:39,758 - root - INFO: \n",
      "2020-11-02 16:15:39,759 - root - INFO: Preprocessing Hydrography\n",
      "2020-11-02 16:15:39,759 - root - INFO: ------------------------------\n",
      "2020-11-02 16:15:39,760 - root - INFO: loading streams in HUC 0601\n",
      "2020-11-02 16:15:39,761 - root - INFO: and/or bounds (273971.0911428096, 3878839.6361173145, 279140.9150949494, 3883953.7853134344)\n",
      "2020-11-02 16:15:39,773 - root - INFO: Using Hydrography file \"/Users/ajc/Core/SimDataInputs/WorkSpace/ats-88/ats_meshing/examples/../data/hydrography/NHDPlus_H_0601_GDB/NHDPlus_H_0601.gdb\"\n",
      "2020-11-02 16:15:55,251 - root - INFO:   ...filtering\n"
     ]
    }
   ],
   "source": [
    "# find the rivers in this shape\n",
    "#call to hilev.py\n",
    "#reaches, _ = workflow.get_rivers_by_bounds(workflow.source_list.hydrography_sources['NHD Plus'],\n",
    "#                                               shply.bounds, shp_profile['crs'], '0601', merge=False)\n",
    "\n",
    "crs, reaches = workflow.get_reaches(workflow.source_list.hydrography_sources['NHD Plus'], '0601',\n",
    "                                               shply.bounds, shp_profile['crs'], long=None, merge=False)\n",
    "\n",
    "# filter the list to only those that intersect the shape\n",
    "reaches = workflow.hydrography.filter_rivers_to_shape(shply, reaches, 10)\n",
    "\n",
    "# make the global tree\n",
    "rivers = workflow.hydrography.make_global_tree(reaches)\n",
    "\n",
    "# check that only one tree was formed (this means al)\n",
    "assert(len(rivers) is 1)\n",
    "river = rivers[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%matplotlib\n",
    "HSV_tuples=['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', \n",
    "            '#fabebe', '#008080', '#e6beff', '#9a6324', '#a9a9a9', '#800000', '#aaffc3', '#808000', '#ffd8b1', \n",
    "            '#000075', '#808080', '#000000', '#009090', '#090770']\n",
    "workflow.plot.rivers([river,], shp_profile['crs'],color=HSV_tuples)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import colorsys\n",
    "#N = 22\n",
    "#HSV_tuples = [(x*1.0/N, x*.1/N, 1.0) for x in range(N)]\n",
    "#RGB_tuples = map(lambda x: colorsys.hsv_to_rgb(*x), HSV_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_NHDPlusID = []\n",
    "for r in river:\n",
    "    #print (r,r.properties)\n",
    "    river_NHDPlusID.append(r.properties['NHDPlusID'])    \n",
    "\n",
    "#print (river_NHDPlusID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ExternalCrosswalk',\n",
       " 'FeatureToMetadata',\n",
       " 'HUMod',\n",
       " 'NHDFCode',\n",
       " 'NHDFeatureToMetadata',\n",
       " 'NHDMetadata',\n",
       " 'NHDPlusDivFracMP',\n",
       " 'NHDPlusEROMMA',\n",
       " 'NHDPlusEROMQAMA',\n",
       " 'NHDPlusEROMQARPT',\n",
       " 'NHDPlusFlow',\n",
       " 'NHDPlusFlowlineVAA',\n",
       " 'NHDPlusIncrLat',\n",
       " 'NHDPlusIncrPrecipMA',\n",
       " 'NHDPlusIncrPrecipMM01',\n",
       " 'NHDPlusIncrPrecipMM02',\n",
       " 'NHDPlusIncrPrecipMM03',\n",
       " 'NHDPlusIncrPrecipMM04',\n",
       " 'NHDPlusIncrPrecipMM05',\n",
       " 'NHDPlusIncrPrecipMM06',\n",
       " 'NHDPlusIncrPrecipMM07',\n",
       " 'NHDPlusIncrPrecipMM08',\n",
       " 'NHDPlusIncrPrecipMM09',\n",
       " 'NHDPlusIncrPrecipMM10',\n",
       " 'NHDPlusIncrPrecipMM11',\n",
       " 'NHDPlusIncrPrecipMM12',\n",
       " 'NHDPlusIncrROMA',\n",
       " 'NHDPlusIncrTempMA',\n",
       " 'NHDPlusIncrTempMM01',\n",
       " 'NHDPlusIncrTempMM02',\n",
       " 'NHDPlusIncrTempMM03',\n",
       " 'NHDPlusIncrTempMM04',\n",
       " 'NHDPlusIncrTempMM05',\n",
       " 'NHDPlusIncrTempMM06',\n",
       " 'NHDPlusIncrTempMM07',\n",
       " 'NHDPlusIncrTempMM08',\n",
       " 'NHDPlusIncrTempMM09',\n",
       " 'NHDPlusIncrTempMM10',\n",
       " 'NHDPlusIncrTempMM11',\n",
       " 'NHDPlusIncrTempMM12',\n",
       " 'NHDPlusMegaDiv',\n",
       " 'NHDPlusNHDPlusIDGridCode',\n",
       " 'NHDProcessingParameters',\n",
       " 'NHDReachCodeMaintenance',\n",
       " 'NHDReachCrossReference',\n",
       " 'NHDSourceCitation',\n",
       " 'NHDVerticalRelationship',\n",
       " 'ProcessingParameters',\n",
       " 'NHDPlusBurnLineEvent',\n",
       " 'NHDPlusBurnWaterbody',\n",
       " 'NHDPlusCatchment',\n",
       " 'NHDPlusLandSea',\n",
       " 'NHDPlusSink',\n",
       " 'NHDPlusWall',\n",
       " 'NHDArea',\n",
       " 'NHDFlowline',\n",
       " 'NHDLine',\n",
       " 'NHDPoint',\n",
       " 'NHDWaterbody',\n",
       " 'MetaProcessDetail',\n",
       " 'MetaSourceDetail',\n",
       " 'NonContributingDrainageArea',\n",
       " 'NonContributingDrainageLine',\n",
       " 'NWISDrainageArea',\n",
       " 'NWISDrainageLine',\n",
       " 'WBDHU10',\n",
       " 'WBDHU12',\n",
       " 'WBDHU14',\n",
       " 'WBDHU16',\n",
       " 'WBDHU2',\n",
       " 'WBDHU4',\n",
       " 'WBDHU6',\n",
       " 'WBDHU8',\n",
       " 'WBDLine',\n",
       " 'HYDRO_NET_Junctions']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fiona\n",
    "fiona.listlayers('../data/hydrography/NHDPlus_H_0601_GDB/NHDPlus_H_0601.gdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14690001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlowlineVAA = fiona.open('../data/hydrography/NHDPlus_H_0601_GDB/NHDPlus_H_0601.gdb', 'r', layer='NHDPlusFlowlineVAA')\n",
    "Flowline = fiona.open('../data/hydrography/NHDPlus_H_0601_GDB/NHDPlus_H_0601.gdb', 'r', layer='NHDFlowline')\n",
    "Flow = fiona.open('../data/hydrography/NHDPlus_H_0601_GDB/NHDPlus_H_0601.gdb', 'r', layer='NHDPlusFlow')\n",
    "Line = fiona.open('../data/hydrography/NHDPlus_H_0601_GDB/NHDPlus_H_0601.gdb', 'r', layer='NHDLine')\n",
    "NHDArea = fiona.open('../data/hydrography/NHDPlus_H_0601_GDB/NHDPlus_H_0601.gdb', 'r', layer='NHDArea')\n",
    "\n",
    "FlowlineVAA[1]['properties']['TotDASqKm']\n",
    "#NHDArea[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHDPLusEROMMA = fiona.open('../data/hydrography/NHDPlus_H_0601_GDB/NHDPlus_H_0601.gdb', 'r', layer='NHDPlusEROMMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "f_vector = lambda p,q: [q[0] - p[0], q[1] - p[1],  q[2] - p[2]]\n",
    "f_distance = lambda p,q: np.sqrt ((p[0] - q[0])**2 + (p[1] - q[1])**2 + (p[2] - q[2])**2)\n",
    "\n",
    "f_normal = lambda v,d: [v[0]/d, v[1]/d, v[2]/d]\n",
    "\n",
    "def get_normal(coords):\n",
    "    pos_v = f_vector(coords[0], coords[1])\n",
    "    distance = math.sqrt(pos_v[0]**2 + pos_v[1]**2 + pos_v[2]**2)\n",
    "    normal = f_normal(pos_v, distance)\n",
    "    normal = [round(n,6) for n in normal]\n",
    "    return normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_to_m = 1000.\n",
    "def River_stream_length():\n",
    "    d2 = []\n",
    "    for r in river:\n",
    "        d1 = [('NHDPlusID',r.properties['NHDPlusID']), \n",
    "              ('LengthKM',r.properties['LengthKM']*km_to_m)]\n",
    "        d2.append(d1)\n",
    "    \n",
    "    d3 = dict()\n",
    "    d3['stream_lengthKM'] = d2\n",
    "    return d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLength = River_stream_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QAMA : Flow from runoff, MA: Mean Annual\n",
    "#VANA : Velocity for QAMA\n",
    "#TotDASqKm: TotalDrainageAreaSqKm [may not be what we want??]\n",
    "\n",
    "def rating_curve(q_cfs,v_fs):\n",
    "    b, f, m = 0.26, 0.40, 0.34\n",
    "    w = x1 * q_cfs**b\n",
    "    d = x2 * q_cfs**f\n",
    "    v = x3 * q_cfs**m\n",
    "    \n",
    "import scipy.signal\n",
    "import geopy.distance\n",
    "\n",
    "\n",
    "def cell_lengths_and_centroids_simple(index,x_spacing=-1,outlet_cell=False,spacing='Uniform'):\n",
    "    length = np.round(Flowline[index]['properties']['LengthKM']*1000,4)\n",
    "    xx = Flowline[index]['properties']['NHDPlusID']\n",
    "    \n",
    "    if (spacing == \"Uniform\"):\n",
    "        if (x_spacing == -1 or length<=x_spacing):\n",
    "            d = 1\n",
    "        else:\n",
    "            d = int(length/x_spacing) + 1\n",
    "            \n",
    "        dx = length/d # ensures all dx sum to the total length\n",
    "        spacing = np.round(np.arange(0,length+dx,dx),4)\n",
    "        cells_spacing = [c for c in spacing if c<=length]\n",
    "        cells_length = cells_spacing[1:] # first cell entity is ignored, zero length\n",
    "        \n",
    "    ncells = len(cells_length) if len(cells_length) > 0 else 1\n",
    "    \n",
    "    sum1 = 0\n",
    "    #print ('Length and spacing: ', cells_spacing[-1], length)\n",
    "    assert (cells_spacing[-1] == length)\n",
    "    #print ('Ncells:', ncells, cells_spacing, length)\n",
    "    x1 = Flowline[index]['geometry']['coordinates'][0]\n",
    "    ncoords = len(x1)\n",
    "    \n",
    "    \n",
    "    c1 = int(ncoords/(ncells))\n",
    "    remain = ncoords%ncells # For Vis only: \"remain\" cells have large volume, nope??\n",
    "    p_index = []\n",
    "    \n",
    "    for i in range(ncells+1):\n",
    "        #print ('Remain: ',i, remain,c1)\n",
    "        if (remain == 0 and ncoords >= ncells):\n",
    "            p_index.append(i*(c1-1))\n",
    "        elif (remain == 0 and ncoords < ncells):\n",
    "            p_index.append(c1-1)\n",
    "        elif i < remain:\n",
    "            #print (i)\n",
    "            p_index.append(i*(c1+1)) \n",
    "        else:\n",
    "            p_index.append(p_index[i-1] + c1)\n",
    "    \n",
    "    edges_coords = []\n",
    "    for p in p_index:\n",
    "        coord = Flowline[index]['geometry']['coordinates'][0][p]\n",
    "        edges_coords.append(coord)\n",
    "        \n",
    "        \n",
    "    centroids = []\n",
    "    #print ('Edges: ', len(edges_coords))\n",
    "    if (x_spacing >0):\n",
    "        for i in range(len(edges_coords)-1,0,-1):\n",
    "            cent = [0.5* (edges_coords[i-1][0] + edges_coords[i][0]), 0.5* (edges_coords[i-1][1] + edges_coords[i][1]), 0]\n",
    "            centroids.append(cent)\n",
    "    else:\n",
    "        # this is for base-case in which the stream length is the cell size\n",
    "        i = 1\n",
    "        cent = [0.5* (edges_coords[i-1][0] + edges_coords[i][0]), 0.5* (edges_coords[i-1][1] + edges_coords[i][1]), 0]\n",
    "\n",
    "        centroids.append(cent)\n",
    "    \n",
    "    cells_spacing = list(cells_spacing)\n",
    "    cells_length1 = [cells_spacing[1],]*len(cells_length)\n",
    "    \n",
    "    if (outlet_cell):\n",
    "        centroids.insert(0, [edges_coords[-1][0] - 0.001,edges_coords[-1][1] + 0.001,0])\n",
    "        cells_spacing = np.insert(cells_spacing,1,25.)\n",
    "        cells_spacing[2] = cells_spacing[2] - 25.\n",
    "        cells_length1 = np.insert(cells_length1,0,25)\n",
    "        cells_length1[1] = cells_length1[1] - 25.\n",
    "    \n",
    "    centroids = list(np.concatenate(centroids))\n",
    "\n",
    "    assert (len(centroids) == 3*len(cells_length1))\n",
    "    #print ('L: ', cells_length1, cells_spacing, len(cells_length1),np.sum(cells_length1))\n",
    "    return centroids, cells_length1, cells_spacing, len(cells_length1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFlow = dict()\n",
    "discharge = []\n",
    "velocity = []\n",
    "\n",
    "Normal = []\n",
    "segment_depth = []\n",
    "segment_length = []\n",
    "segment_width = []\n",
    "segment_crossA = []\n",
    "\n",
    "km_to_m = 1000.\n",
    "cfs_to_ms = 0.028316847 # QAMA is in cfs, convert cfs to m/s\n",
    "fs_to_ms = 0.3048\n",
    "\n",
    "# get discharge, velocity, depth, and orientation\n",
    "\n",
    "def River_Characteristics(x_spacing_=-1.):\n",
    "    d4 = []\n",
    "    d5 = []\n",
    "    d6 = []\n",
    "    add_outlet_cell = True\n",
    "    if x_spacing_ <=25.:\n",
    "        add_outlet_cell = False\n",
    "    for k,r in enumerate(river):\n",
    "        \n",
    "        for i in range(len(NHDPLusEROMMA)):\n",
    "            if NHDPLusEROMMA[i+1]['properties']['NHDPlusID'] == r.properties['NHDPlusID']:\n",
    "                \n",
    "                id = r.properties['NHDPlusID']\n",
    "                \n",
    "                value_q = NHDPLusEROMMA[i+1]['properties']['QAMA']*cfs_to_ms\n",
    "                discharge.append([('NHDPlusID',id), ('Discharge [m^3/s]',value_q)])\n",
    "                \n",
    "                value_v = NHDPLusEROMMA[i+1]['properties']['VAMA']*fs_to_ms\n",
    "                velocity.append([('NHDPlusID',id), ('Velocity [m/s]',value_v)])\n",
    "                \n",
    "                length = r.properties['LengthKM']*km_to_m\n",
    "                \n",
    "                cross_area = value_q/value_v#FlowlineVAA[i+1]['properties']['TotDASqKm']\n",
    "                                \n",
    "                \n",
    "                width = 1.0 #area/length*km_to_m\n",
    "                height = cross_area * fs_to_ms #value_q/(value_v * width) \n",
    "                \n",
    "                segment_length.append([('NHDPlusID',id), ('segment length [m]', length)])\n",
    "                segment_depth.append([('NHDPlusID',id), ('segment depth [m]', height)])\n",
    "                segment_width.append([('NHDPlusID',id), ('segment width [m]', width)])\n",
    "                segment_crossA.append([('NHDPlusID',id), ('segment width [m]', cross_area * fs_to_ms)])\n",
    "                \n",
    "                # orientation\n",
    "                #if Flowline[i+1]['properties']['NHDPlusID'] == r.properties['NHDPlusID']:\n",
    "                p = Flowline[i+1]['geometry']['coordinates'][0][0]\n",
    "                q = Flowline[i+1]['geometry']['coordinates'][0][-1] #note coord are in reverse order in NHD \n",
    "                print (k, r.properties['NHDPlusID'],length)\n",
    "                n = get_normal([p,q])\n",
    "                Normal.append([n[0],n[1],n[2]])\n",
    "                \n",
    "                # get number of cells and centroids\n",
    "                \n",
    "                \n",
    "                \n",
    "                #coordy = Flowline[i+1]['geometry']['coordinates']\n",
    "                d4.append([('NHDPlusID',id), ('Discharge [m^3/s]',value_q),\n",
    "                           ('Velocity [m/s]',value_v), ('segment length [m]', length),\n",
    "                           ('segment depth [m]', height),\n",
    "                           ('segment width [m]', width), ('orientation', [n[0],n[1],n[2]] )])\n",
    "    \n",
    "        \n",
    "        for j in range(len(Flowline)):\n",
    "            if Flowline[j+1]['properties']['NHDPlusID'] == r.properties['NHDPlusID']:\n",
    "                if (add_outlet_cell == True and k==0):\n",
    "                    centroids, cell_lengths, cell_spacing, ncells = cell_lengths_and_centroids_simple(j+1,x_spacing_,outlet_cell=add_outlet_cell)\n",
    "                else:\n",
    "                    centroids, cell_lengths, cell_spacing, ncells = cell_lengths_and_centroids_simple(j+1,x_spacing_)\n",
    "                d5.append([('NHDPlusID',id), ('centroids', centroids),\n",
    "                           ('cell lengths [m]', cell_lengths), ('cell spacing [m]', cell_spacing),\n",
    "                           ('number of cells', ncells)])\n",
    "                #break\n",
    "                \n",
    "        \n",
    "        for j in range(len(FlowlineVAA)):\n",
    "            if FlowlineVAA[j+1]['properties']['NHDPlusID'] == r.properties['NHDPlusID']:\n",
    "                contrib_area =  FlowlineVAA[j+1]['properties']['TotDASqKm'] * km_to_m\n",
    "                d6.append([('NHDPlusID',id), ('Contributing area', contrib_area)])\n",
    "    \n",
    "        #break\n",
    "    return d4, d5, d6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_spacing_=100\n",
    "Data_NHD_ATS, DataMesh_NHD_ATS, DataArea_NHD_ATS  = River_Characteristics(x_spacing_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Streams_connectivity():\n",
    "    Node = []\n",
    "    for r in river:\n",
    "        for i in range(len(FlowlineVAA)):\n",
    "            if FlowlineVAA[i+1]['properties']['NHDPlusID'] == r.properties['NHDPlusID']:\n",
    "                id = r.properties['NHDPlusID']\n",
    "                from_node = FlowlineVAA[i+1]['properties']['FromNode']\n",
    "                to_node = FlowlineVAA[i+1]['properties']['ToNode']\n",
    "                \n",
    "                Node.append([('NHDPlusID',id), ('FromNode',from_node),('ToNode',to_node)])\n",
    "    Nodes = dict()\n",
    "    Nodes['connectivity'] = Node\n",
    "    return Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Connectivity = dict()\n",
    "Connectivity_Orig = Streams_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "pairs = [(1, 2),(2, 3),(3, 4), (3, 5),(5, 9),(5, 7), (2, 8), (8,10), (8,11)]\n",
    "\n",
    "graph_syn = nx.from_edgelist(pairs)\n",
    "print (graph_syn.nodes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coweeta_pairs = []\n",
    "\n",
    "NHD_Id_Index = []\n",
    "for i,n in enumerate(Connectivity_Orig['connectivity']):\n",
    "    NHD_Id_Index.append([n[0][1],i+1])\n",
    "    coweeta_pairs.append((int(n[2][1]),int(n[1][1])))\n",
    "Coweeta_Graph = nx.from_edgelist(coweeta_pairs)\n",
    "\n",
    "coweeta_pairs_index = []\n",
    "node_index_pair = []\n",
    "\n",
    "for i,node in enumerate(Coweeta_Graph):\n",
    "    node_index_pair.append((node,i+1))\n",
    "\n",
    "def get_index_from_node(node):\n",
    "    for n in node_index_pair:\n",
    "        if node == n[0]:\n",
    "            #print ('from node', node,n)\n",
    "            break\n",
    "    return n[1]\n",
    "\n",
    "def get_node_from_index(index):\n",
    "    for n in node_index_pair:\n",
    "        if index == n[1]:\n",
    "            break\n",
    "    return n[0]\n",
    "\n",
    "for n in Connectivity_Orig['connectivity']:\n",
    "    x1 = get_index_from_node(int(n[2][1]))\n",
    "    x2 = get_index_from_node(int(n[1][1]))\n",
    "    coweeta_pairs_index.append((x1,x2))\n",
    "    \n",
    "Coweeta_Graph1 = nx.from_edgelist(coweeta_pairs_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeDiagnostic(graph):\n",
    "    for node in graph:\n",
    "        edges,_ = node_get_upstream_edges(graph,[node])\n",
    "        for edge in edges:\n",
    "            print (edge)\n",
    "            assert edge[0] < edge[1]\n",
    "\n",
    "def numNodes(graph):\n",
    "    return len(graph.nodes)\n",
    "\n",
    "\n",
    "def isNeighborNode(graph,node):\n",
    "    ngh_nodes = list(graph.neighbors(node))\n",
    "    return  True if len(ngh_nodes) > 0 else False\n",
    "\n",
    "def node_get_edges(graph, node):\n",
    "    \n",
    "    edges = list(nx.edge_boundary(graph, node))\n",
    "    return edges\n",
    "\n",
    "def node_get_upstream_edges(graph, node):\n",
    "    edges = list(nx.edge_boundary(graph, node))\n",
    "    parent = -100\n",
    "    for i,edge in enumerate(edges):\n",
    "        if edge[0] > edge[1]:\n",
    "            parent = edges[i]\n",
    "            edges.pop(i)\n",
    "    return edges, parent\n",
    "\n",
    "def isNeighborBoundaryNode(graph, edge):\n",
    "    ngh = list(graph.neighbors(edge[1]))\n",
    "    return False if len(ngh) > 1 else True\n",
    "\n",
    "def isBoundaryNode(graph, node):\n",
    "    assert (node != 1)\n",
    "    ngh = list(graph.neighbors(node))\n",
    "    return False if len(ngh) > 1 else True\n",
    "\n",
    "def get_node_index(graph, node):\n",
    "    x = np.where(np.array(graph.nodes) == node)[0][0] + 1\n",
    "    return x\n",
    "\n",
    "def index_based_graph(graph):\n",
    "    Nodes_new_ids = np.linspace(1,len(graph),len(graph), dtype='i')\n",
    "    Nodes = graph.nodes\n",
    "\n",
    "def implied_source_Raymond(Q, Contri_A,ncells, cell_area,mass_isconstant=False):\n",
    "    #cell area is passed, and can be used if required\n",
    "    g = 1020\n",
    "    h = 0.345\n",
    "    if (mass_isconstant):\n",
    "        molar_mass = 1\n",
    "    rho_molar = 1.0 #55555.55 # this is made one for chemistry since in ATS transport runs we use molar density 1 but for chemisty water density is 1000\n",
    "    rho_water = 1000.0\n",
    "    mass_molar = 1#rho_water / rho_molar  #[kg/moles]\n",
    "\n",
    "    Qreach = Q[-1] # discharge at the first order stream outlet\n",
    "    Source = np.zeros(len(Q)-1)\n",
    "    #print ('Source: ',len(Source), len(cell_area), len(Q))\n",
    "    for i in range(len(Q)-1):\n",
    "        del_q = Q[i+1] - Q[i]\n",
    "        \n",
    "        C = np.round(g * (Qreach / (Contri_A * 8.64E+8) )**h,6)\n",
    "        #print ('Qout=', Q[i+1], ' Qin = ',Q[i], ' dQ=',del_q, ' Cont=',C)\n",
    "        Source[i] = ncells*(del_q * C) / mass_molar #/cell_area[i] # conver source [kg/sec] to [moles/sec]\n",
    "       \n",
    "        \n",
    "    return Source\n",
    "\n",
    "def implied_source(Q, molar_mass=1):\n",
    "    #cell area is passed, and can be used if required\n",
    "    if (molar_mass > 1):\n",
    "        rho_molar = 1.0 #55555.55 # this is made one for chemistry since in ATS transport runs we use molar density 1 but for chemisty water density is 1000\n",
    "        rho_water = 1000.0\n",
    "        molar_mass = rho_water / rho_molar  #[kg/moles]\n",
    "    \n",
    "    Source = np.zeros(len(Q)-1)\n",
    "    #print ('Source: ',len(Source), len(cell_area), len(Q))\n",
    "    for i in range(len(Q)-1):\n",
    "        del_q = Q[i+1] - Q[i]\n",
    "        Source[i] = del_q / molar_mass #/cell_area[i] # conver source [kg/sec] to [moles/sec]\n",
    "       \n",
    "        \n",
    "    return Source\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000/0.018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = '/Users/ajc/Core/PreProcessData/Transport/2020/Coweeta_meshes_outletcell/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import lxml.builder\n",
    "import lxml.etree as ET\n",
    "\n",
    "num_nodes = numNodes(Coweeta_Graph1)\n",
    "fine_roots = []\n",
    "\n",
    "Discharge =  []\n",
    "CrossSectionArea = []\n",
    "BoundaryCells = []\n",
    "BoundaryReachCells = []\n",
    "Total_cells = 0\n",
    "#add_outlet_cell = True # fix sized cell at the outlet (adds one cell n) \n",
    "\n",
    "def WriteXMLNHD_Centroid(write=True):\n",
    "    global Total_cells\n",
    "    index = 0\n",
    "    root = ET.Element(\"ParameterList\", name=\"Main\")\n",
    "    ET.SubElement(root,\"Parameter\",name=\"infer cell centroids\",type=\"bool\", value=\"true\")\n",
    "    segments = ET.SubElement(root,\"ParameterList\", name=\"segments\")\n",
    "    #---- for regions\n",
    "    root_region = ET.Element(\"ParameterList\", name=\"Main\")\n",
    "    #--------\n",
    "    nam = ''\n",
    "    node_id_root = 0\n",
    "    total_cells = 0\n",
    "    bc_cell_id = 0\n",
    "    tt = 0\n",
    "    for i,node in enumerate(Coweeta_Graph1):\n",
    "        \n",
    "        length = Data_NHD_ATS[i][3][1]\n",
    "        width = 1#Data_NHD_ATS[i][5][1]\n",
    "        orientation = (1,0,0)#Data_NHD_ATS[i][6][1]\n",
    "        cross_area = Data_NHD_ATS[i][4][1]\n",
    "        \n",
    "        centroids = DataMesh_NHD_ATS[i][1][1]\n",
    "        cell_lengths = DataMesh_NHD_ATS[i][2][1]\n",
    "        ncells = DataMesh_NHD_ATS[i][4][1]\n",
    "        \n",
    "        total_cells = total_cells + ncells\n",
    "        \n",
    "        if i ==0:\n",
    "            index = 0\n",
    "            node_id_root = node\n",
    "                       \n",
    "            edges = node_get_edges(Coweeta_Graph1,[node])[0]\n",
    "            \n",
    "            nam = 'stream_' + str(edges[0]) + '_' + str(edges[1])\n",
    "           \n",
    "            streams = ET.SubElement(segments,\"ParameterList\", name=\"%s\"%nam)\n",
    "            ET.SubElement(streams, \"Parameter\", name=\"segment length [m]\", type=\"double\", value=\"%s\"%length)\n",
    "            \n",
    "            ET.SubElement(streams,\"Parameter\",name=\"number of cells\", type=\"int\", value=\"%s\"%ncells)\n",
    "            \n",
    "            n1,n2 = orientation[0],orientation[1]\n",
    "            \n",
    "            ET.SubElement(streams,\"Parameter\",name=\"orientation\", type=\"Array(double)\", value=\"{%s,%s,0}\"%(n1,n2))\n",
    "            ET.SubElement(streams,\"Parameter\",name=\"cross sectional area [m^2]\", type=\"double\", value=\"%s\"%cross_area)\n",
    "            ET.SubElement(streams,\"Parameter\",name=\"first tip type\", type=\"string\", value=\"boundary\")\n",
    "            ET.SubElement(streams,\"Parameter\",name=\"last tip type\", type=\"string\", value=\"junction\")\n",
    "            ET.SubElement(streams,\"Parameter\",name=\"cell centroids\", type=\"Array(double)\", value=\"{%s}\"%\", \".join(map(str,centroids)))\n",
    "            ET.SubElement(streams,\"Parameter\",name=\"cell lengths [m]\", type=\"Array(double)\", value=\"{%s}\"% \", \".join(map(str,cell_lengths)))\n",
    "            \n",
    "            Discharge.append(Data_NHD_ATS[index][1][1])\n",
    "            #print (Discharge)\n",
    "            #break\n",
    "            CrossSectionArea.append(Data_NHD_ATS[index][4][1])\n",
    "            bc_cell_id = bc_cell_id + ncells\n",
    "            tt  = tt + ncells\n",
    "            r_ids = [-1 for i1 in range(ncells)] \n",
    "            BoundaryReachCells.append(r_ids)\n",
    "            #print (ncells)\n",
    "        else:\n",
    "            edges, parent = node_get_upstream_edges(Coweeta_Graph1,[node])\n",
    "           \n",
    "            edge_len = len(edges)\n",
    "            \n",
    "            if edge_len == 0: #boundary edge\n",
    "                continue\n",
    "                \n",
    "            for j, child_node in enumerate(edges):\n",
    "                \n",
    "                if child_node[1] != node_id_root:\n",
    "                    index = child_node[1] - 2 \n",
    "                    index_parent = child_node[0] - 2 \n",
    "                    nam = 'stream_' + str(child_node[0]) + '_' + str(child_node[1])\n",
    "                    streams = ET.SubElement(segments,\"ParameterList\", name=\"%s\"%nam)\n",
    "                   \n",
    "                    centroids = DataMesh_NHD_ATS[index][1][1]\n",
    "                    cell_lengths = DataMesh_NHD_ATS[index][2][1]\n",
    "                    ncells = DataMesh_NHD_ATS[index][4][1]\n",
    "                    cross_area = Data_NHD_ATS[index][4][1]\n",
    "                    length = Data_NHD_ATS[index][3][1]\n",
    "                    \n",
    "                    ET.SubElement(streams,\"Parameter\",name=\"first tip type\", type=\"string\", value=\"branch\")\n",
    "                    ET.SubElement(streams,\"Parameter\",name=\"first tip branch segment\", type=\"string\", value=\"stream_%s_%s\"%(parent[1],parent[0]))\n",
    "                    ET.SubElement(streams,\"Parameter\",name=\"first tip branch segment tip\", type=\"string\", value=\"last\")\n",
    "                    \n",
    "                    if isBoundaryNode(Coweeta_Graph1,child_node[1]):\n",
    "                        ET.SubElement(streams,\"Parameter\",name=\"last tip type\", type=\"string\", value=\"boundary\")\n",
    "                    else:\n",
    "                        ET.SubElement(streams,\"Parameter\",name=\"last tip type\", type=\"string\", value=\"junction\")\n",
    "                        \n",
    "                    n1,n2 = orientation[0],orientation[1]\n",
    "                    \n",
    "                    ET.SubElement(streams,\"Parameter\",name=\"orientation\", type=\"Array(double)\", value=\"{%s,%s,0}\"%(n1,n2))\n",
    "                    ET.SubElement(streams, \"Parameter\", name=\"segment length [m]\", type=\"double\", value=\"%s\"%length)\n",
    "                    ET.SubElement(streams,\"Parameter\",name=\"number of cells\", type=\"int\", value=\"%s\"%ncells) \n",
    "                    ET.SubElement(streams,\"Parameter\",name=\"cross sectional area [m^2]\", type=\"double\", value=\"%s\"%cross_area)\n",
    "                    ET.SubElement(streams,\"Parameter\",name=\"cell centroids\", type=\"Array(double)\", value=\"{%s}\"%\", \".join(map(str,centroids)))\n",
    "                    ET.SubElement(streams,\"Parameter\",name=\"cell lengths [m]\", type=\"Array(double)\", value=\"{%s}\"% \", \".join(map(str,cell_lengths)))\n",
    "                    \n",
    "                    fine_roots.append(nam)\n",
    "                    Discharge.append(Data_NHD_ATS[index][1][1])\n",
    "                    CrossSectionArea.append(Data_NHD_ATS[index][4][1])\n",
    "                    \n",
    "                    bc_cell_id = bc_cell_id + ncells\n",
    "                    # get boundary nodes ids\n",
    "                    tt  = tt + ncells\n",
    "                    #print (ncells)\n",
    "                    if isBoundaryNode(Coweeta_Graph1,child_node[1]):\n",
    "                        \n",
    "                        BoundaryCells.append(bc_cell_id-1)\n",
    "                        r_ids = [bc_cell_id -1 - i1 for i1 in range(ncells)] \n",
    "                        BoundaryReachCells.append(r_ids)\n",
    "                        #print (nam, Discharge[-1],ncells,BoundaryReachCells[-1])\n",
    "                        reach_region = ET.SubElement(root_region,\"ParameterList\", name=\"%s\"%nam)\n",
    "                        ET.SubElement(reach_region,\"Parameter\",name=\"entity\", type=\"string\", value=\"cell\")\n",
    "                        ET.SubElement(reach_region,\"Parameter\",name=\"entity gids\", type=\"Array(int)\", value=\"{%s}\"%\", \".join(map(str,r_ids)))\n",
    "                    else:\n",
    "                        r_ids = [-1 for i1 in range(ncells)] \n",
    "                        BoundaryReachCells.append(r_ids)\n",
    "                    i = i + j\n",
    "                #\n",
    "            #\n",
    "        #\n",
    "        Total_cells = tt\n",
    "        \n",
    "        if (i+2 >= len(Coweeta_Graph1)):\n",
    "            break\n",
    "    sets = ET.SubElement(root,\"ParameterList\",name=\"sets\",type=\"bool\", value=\"true\")\n",
    "    ET.SubElement(sets,\"Parameter\",name=\"fine_root\",type=\"Array(string)\", value=\"{%s}\"%\", \".join(map(str,fine_roots)))\n",
    "    Data= etree.tostring(root,encoding=\"unicode\",pretty_print=True)\n",
    "    Data_regions = etree.tostring(root_region,encoding=\"unicode\",pretty_print=True)\n",
    "    \n",
    "    outfile= open(outpath+ '/mesh_coweeta_mc-%sm.xml'%int(x_spacing_),'w') #mc for meshconvergence\n",
    "    outfile.write(Data)\n",
    "    \n",
    "    #write xml file for 1st order stream\n",
    "    outfile= open(outpath + '/regions_coweeta_mc-%sm.xml'%int(x_spacing_),'w') # reach length is the cell length\n",
    "    outfile.write(Data_regions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WriteXMLNHD_Centroid(write=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoundaryCells\n",
    "#BoundaryReachCells\n",
    "#Total_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.061198907756493/len(BoundaryReachCells[8])\n",
    "# S_i = dQ/N * Co, dQ = Qout - Qin, N=len(reach), Co = concentrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discharge =  []\n",
    "CrossSectionArea = []\n",
    "BoundaryCells = []\n",
    "ImpliedSourceTemp = [] #np.zeros((Total_cells))\n",
    "ImpliedSource = np.zeros((Total_cells))\n",
    "\n",
    "#def check_uniformity(fflux):\n",
    "#    all(np.diff(fflux)==np.diff(a)[0])\n",
    "    \n",
    "    \n",
    "def Linearize_Discharge():\n",
    "    QQ = []\n",
    "    index = 0\n",
    "    count = 0\n",
    "    \n",
    "    total_cells = 0\n",
    "    map_id = []\n",
    "    map_id.append(0)\n",
    "    for i,node in enumerate(Coweeta_Graph1):\n",
    "        if i ==-1:\n",
    "            index = 0\n",
    "            node_id_root = node\n",
    "            Discharge.append(Data_NHD_ATS[index][1][1])\n",
    "        else:\n",
    "            edges, parent = node_get_upstream_edges(Coweeta_Graph1,[node])\n",
    "            edge_len = len(edges)\n",
    "            \n",
    "            if (parent == -100):\n",
    "                continue\n",
    "            else:\n",
    "                index_parent = parent[0] - 2\n",
    "            \n",
    "            #summing Qin\n",
    "            #------------------------------------------------\n",
    "            Qin = 0\n",
    "            \n",
    "            for edg in edges:\n",
    "                index1 = edg[1]-2\n",
    "                Qin = Qin + Data_NHD_ATS[index1][1][1] # Discharge\n",
    "                \n",
    "                \n",
    "                count = count + 1\n",
    "                map_id.append(index1)\n",
    "            Boundary_Node = False\n",
    "            if (edge_len==0): # boundary node\n",
    "                \n",
    "                Qin = 0\n",
    "                Boundary_Node = True\n",
    "                \n",
    "                \n",
    "            #------------------------------------------------\n",
    "            Qout=Data_NHD_ATS[index_parent][1][1] # Dischage\n",
    "            \n",
    "            \n",
    "            length = Data_NHD_ATS[index_parent][3][1] \n",
    "            centroids = DataMesh_NHD_ATS[index_parent][1][1]\n",
    "            cell_spacing = np.round(DataMesh_NHD_ATS[index_parent][3][1],2)\n",
    "            ncells = DataMesh_NHD_ATS[index_parent][4][1]\n",
    "            cell_lengths = DataMesh_NHD_ATS[index_parent][2][1]\n",
    "            \n",
    "            \n",
    "            m = (Qout - Qin)/length\n",
    "            #print ('Spacing: ',cell_spacing)\n",
    "            \n",
    "            flux_f_orig = [round(Qin + m*x,5) for x in cell_spacing]\n",
    "            #print (flux_f_orig)\n",
    "            \n",
    "            total_cells = total_cells + ncells\n",
    "            # compute velocities\n",
    "            cross_area = Data_NHD_ATS[index_parent][4][1]\n",
    "            Velocity = Qout/(cross_area*cell_spacing[1])\n",
    "                \n",
    "            if not Boundary_Node:\n",
    "                flux_f = flux_f_orig[1:]\n",
    "                #print ('V: ',cross_area,Velocity)\n",
    "            else:\n",
    "                flux_f = flux_f_orig\n",
    "                #print ('V-b: ',cross_area ,Velocity)\n",
    "            \n",
    "            #rr = all(np.diff(flux_f)==np.diff(flux_f)[0])\n",
    "            #rrr = all(np.diff(cell_spacing)==np.diff(cell_spacing)[1])\n",
    "            \n",
    "            #print ('FLUX: ',flux_f)\n",
    "            QQ.append(flux_f[::-1])\n",
    "            #print (cell_lengths)\n",
    "            cont_area = DataArea_NHD_ATS[index_parent][1][1]\n",
    "            \n",
    "            if Boundary_Node:\n",
    "                #source = implied_source_Raymond(flux_f_orig,cont_area,ncells,cell_lengths,mass_isconstant=True)\n",
    "                source = implied_source(flux_f_orig,molar_mass=1)\n",
    "            else:\n",
    "                source = implied_source(flux_f_orig,molar_mass=1)\n",
    "                source = 1*source* 1 #this should be zero for first order streams implied source only\n",
    "            #print ('source ', index_parent, len(source),len(flux_f), flux_f[-1],flux_f[0],map_id[-1],)\n",
    "            #print (Qout, Qin, length, ncells, len(flux_f), QQ)\n",
    "            #print ('----------------------------------')\n",
    "            ImpliedSourceTemp.append(source)\n",
    "            #print (ncells, len(source))\n",
    "            #print(source)\n",
    "            #print('-------------------')\n",
    "            print ('HERE: ',ncells, source)\n",
    "            \n",
    "            #break    \n",
    "    \n",
    "    Q2 = []\n",
    "    s11=0\n",
    "    for i in range(0,len(QQ)): # to get the fluxes consistent with ATS faces\n",
    "        Q2.append(QQ[map_id[i]])\n",
    "        #print (len(QQ[map_id[i]]), map_id[i], QQ[map_id[i]][0],QQ[map_id[i]][-1])\n",
    "        s11=s11+len(QQ[map_id[i]])\n",
    "        \n",
    "    full_watershed_implied_source = True\n",
    "    first_order_reach = True\n",
    "    \n",
    "    if (full_watershed_implied_source):\n",
    "        first_order_reach = False\n",
    "    c = 0\n",
    "    for i,d in enumerate(ImpliedSourceTemp):\n",
    "        if (full_watershed_implied_source):\n",
    "            \n",
    "            #ImpliedSource = np.concatenate(ImpliedSourceTemp)\n",
    "            \n",
    "            for s in ImpliedSourceTemp[map_id[i]]:\n",
    "                #print (c, map_id[i] ,s)\n",
    "                ImpliedSource[c] =  s\n",
    "                c = c +1\n",
    "        elif (first_order_reach):\n",
    "            for c,s in zip(BoundaryReachCells[i],ImpliedSourceTemp[map_id[i]]):\n",
    "                ImpliedSource[c] =  s\n",
    "                #print (i,c,s,map_id[i], len(ImpliedSourceTemp),len(BoundaryReachCells))\n",
    "                if (not first_order_reach):\n",
    "                    break # break if only injecting at the boundary cell\n",
    "        elif (not first_order_reach):\n",
    "            for c,s in zip(BoundaryReachCells[i],ImpliedSourceTemp[map_id[i]]):\n",
    "                ImpliedSource[c] =  s\n",
    "                #print (i,c,s,map_id[i], len(ImpliedSourceTemp),len(BoundaryReachCells))\n",
    "          \n",
    "                break # break if only injecting at the boundary cell\n",
    "        \n",
    "    print(ImpliedSource)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Q1 = np.concatenate(Q2,axis=0)\n",
    "    #np.savetxt(outpath+ \"/flux_interpolate-%sm.dat\"%int(x_spacing_), Q1)\n",
    "    np.savetxt(outpath + \"/implied_source_full-%sm.dat\"%int(x_spacing_), ImpliedSource)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linearize_Discharge()\n",
    "#0.9080831404970909 0.8069423289574529 2825.0 15 15 # 200m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test200 = ImpliedSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = ImpliedSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Test200)\n",
    "print (BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x200=0.01435516*6\n",
    "xbase = 0.08613093\n",
    "print (x200,xbase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
